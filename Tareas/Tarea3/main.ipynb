{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea 3 - Inteligencia artificial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'/home/ubuntu/inteligencia_artificial/Tareas/Tarea 3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item 1\n",
    "Importo dataset (10 puntos)\n",
    "Fuente: https://www.kaggle.com/datasets/ayessa/salary-prediction-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age          workclass  fnlwgt   education  education-num  \\\n",
      "0   39          State-gov   77516   Bachelors             13   \n",
      "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
      "2   38            Private  215646     HS-grad              9   \n",
      "3   53            Private  234721        11th              7   \n",
      "4   28            Private  338409   Bachelors             13   \n",
      "\n",
      "        marital-status          occupation    relationship    race      sex  \\\n",
      "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
      "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
      "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
      "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
      "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
      "\n",
      "   capital-gain  capital-loss  hours-per-week  native-country  salary  \n",
      "0          2174             0              40   United-States   <=50K  \n",
      "1             0             0              13   United-States   <=50K  \n",
      "2             0             0              40   United-States   <=50K  \n",
      "3             0             0              40   United-States   <=50K  \n",
      "4             0             0              40            Cuba   <=50K  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(21999, 15)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "dataset = pd.read_csv(\"./dataset/train22k.csv\")\n",
    "print(dataset.head())\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item 2\n",
    "Entrene el algoritmo KNN sobre los datos seleccionados y aplique predicciones con algún (sub)conjunto DISJUNTO de prueba. Adicionalmente, utilice 3 métricas (a su elección) de error y compárelas entre sí. (15 ptos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.7954932777882977\n",
      "hamming_loss: 0.20450672221170232\n",
      "jaccard_score: 0.20471281296023564\n",
      "Confusion matrix:\n",
      " [[7846  115]\n",
      " [2045  556]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\"\"\" el siguiente es para asociar strings a numeros \"\"\"\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "#print(type(dataset.iloc[0,1]))\n",
    "#print(isinstance(dataset.iloc[0,1], str))\n",
    "#print(dataset.head())\n",
    "\"\"\" Declaro el encoder de string a numeros \"\"\"\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "def column_string_to_int(columnas, dataset_validation):\n",
    "     \"\"\" For para iterar el dataset en columnas\"\"\"\n",
    "     for i in range(columnas):\n",
    "          \"\"\"  \n",
    "          En realidad el dataset es un dataframe de pandas, este tiene propiedades para\n",
    "          acceder a él. 'iloc' sirve para acceder a él como una matriz con indices\n",
    "          de fila y columna [x,y].\n",
    "\n",
    "          Con isisntance() puedo ver si la primera fila de datos en cada columna es un string,\n",
    "          ya que en estos casos debo aplicar la conversion a números \"\"\"\n",
    "          if isinstance(dataset_validation.iloc[0,i], str):\n",
    "               \"\"\"\n",
    "               Con dataset.columns[i] obtengo el nombre de la columna,\n",
    "               luego convierto esa columna completa en números \"\"\"\n",
    "               string = dataset_validation.columns[i]\n",
    "               dataset_validation[string] = encoder.fit_transform(dataset_validation[string])\n",
    "\n",
    "def best_k(x_train, y_train, x_test, y_test, max_k):\n",
    "     best_k = 0\n",
    "     best_score = 0\n",
    "     for i in range(max_k):\n",
    "          i = i+1\n",
    "          knn = KNeighborsClassifier(n_neighbors=i)\n",
    "          knn.fit(x_train, y_train)\n",
    "          score = knn.score(x_test, y_test)\n",
    "          if best_score < score:\n",
    "               best_score = score\n",
    "               best_k = i\n",
    "          print(\"Procesando actualmente K=\",i,\", mejor k=\",best_k, \", mayor precision: \", best_score)\n",
    "\n",
    "column_string_to_int(15, dataset)\n",
    "\n",
    "x = dataset.iloc[:, :14].values\n",
    "\n",
    "y = dataset['salary'].values\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=17)\n",
    "\n",
    "knn.fit(x, y)\n",
    "#Realizo una predicción\n",
    "\n",
    "dataset_validation = pd.read_csv(\"./dataset/validation.csv\")\n",
    "column_string_to_int(15, dataset_validation)\n",
    "\n",
    "x_validation = dataset_validation.iloc[:, :14].values\n",
    "y_validation = dataset_validation['salary'].values\n",
    "\n",
    "#knn.predict(x_validation[1].reshape(1,-1))[0]\n",
    "#best_k(x,y,x_validation,y_validation,4)\n",
    "\n",
    "#Predice los resultados \"y\" respecto a la matriz \"x\" de validación (x_validation)\n",
    "y_pred = knn.predict(x_validation)\n",
    "\n",
    "score_train = knn.score(x,y)\n",
    "score_validation = knn.score(x_validation,y_validation)\n",
    "\"\"\" print(\"Score_train: \", score_train)\n",
    "print(\"score_validation: \", score_validation) \"\"\"\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "print(\"accuracy_score:\", metrics.accuracy_score(y_validation, y_pred))\n",
    "print(\"hamming_loss:\", metrics.hamming_loss(y_validation, y_pred))\n",
    "print(\"Confusion matrix:\\n\", metrics.confusion_matrix(y_validation, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis\n",
    "\n",
    "Se seleccionaron las siguientes tres  metricas de error:\n",
    "1. **Accuracy score:** Corresponde a la probabilidad de predicciones correctas del modelo ya entrenado. Para ello le damos como parámetros una matriz $x$ que corresponde a los datos en los que se basa el modelo (Son nuevos datos distintos a los de entrenamiento, aunque también se puede ver con los datos de entrenamiento) para generar predicciones y un parámetro $y$ que corresponde a los resultados correctos. Así el output de esta función es:\n",
    "\n",
    "     (total_de_resultados_correctamente_acertados) / (total_de_resultados_correctos)\n",
    "\n",
    "2. **Hamming loss:** Corresponde a la distancia de hamming (etiquetas incorrectas / numero total de etiquetas ) entre los parámetros y_validation e y_pred.\n",
    "3. **Matriz de confusión:** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item 3\n",
    "Entrene el algoritmo de Regresión Lineal ahora con los mismos datos seleccionados, aplicando también predicciones sobre el mismo (sub)conjunto DISJUNTO de prueba de la parte anterior. Elija alguna métrica de error de entre las tres de la parte anterior y compare los errores, dando una explicación de qué sucede. (15 ptos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score_train:  0.25645056075503647\n",
      "score_validation:  0.2729230256309212\n",
      "1.2753269315778546\n"
     ]
    }
   ],
   "source": [
    "# Imports necesarios\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "plt.rcParams['figure.figsize'] = (16, 9)\n",
    "plt.style.use('ggplot')\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "#cargamos los datos de entrada\n",
    "data = pd.read_csv(\"./dataset/train22k.csv\")\n",
    "#veamos cuantas dimensiones y registros contiene\n",
    "data\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "\n",
    "\n",
    "column_string_to_int(15, data)\n",
    "\n",
    "# Asignamos nuestra variable de entrada X para entrenamiento y las etiquetas Y.\n",
    "\n",
    "X_train = data.iloc[:, :14].values\n",
    "#Nocumple = db[db.salary.str.contains('<=50K')]\n",
    "\n",
    "y_train = data['salary'].values\n",
    "\n",
    "# Creamos el objeto de Regresión Linear\n",
    "regr = linear_model.LinearRegression()\n",
    " \n",
    "# Entrenamos nuestro modelo\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred = regr.predict(X_train)\n",
    "#llamamos otro dataset...\n",
    "data_validation = pd.read_csv(\"./dataset/validation.csv\")\n",
    "\n",
    "column_string_to_int(15, data_validation)\n",
    "\n",
    "#print(dataset_validation.head())\n",
    "X_train_validation = data_validation.iloc[:, :14].values\n",
    "y_train_validation = data_validation['salary'].values\n",
    "y_pred1 = regr.predict(X_train_validation)\n",
    "\"\"\" Los datos de salario <=50k son 0 y los >50 son 1 \"\"\"\n",
    "\n",
    "#metricas score...\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "score_train1 = metrics.r2_score(y_train, y_pred)\n",
    "score_validation1 = metrics.r2_score(y_train_validation, y_pred1)\n",
    "\n",
    "print(\"Score_train: \", score_train1)\n",
    "print(\"score_validation: \", score_validation1)\n",
    "\n",
    "print(metrics.max_error(y_train_validation, y_pred1))\n",
    "#listoco...\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item 4\n",
    "Tome su mismo dataset y entrene dos algoritmos de clasificación: Gaussian Mixture Model y DBSCAN. Evalúe estos algoritmos sobre el mismo (sub)conjunto DISJUNTO de las partes 2 y 3. Analice la diferencia en los resultados entre los algoritmos (10 ptos). Asimismo, indique y aporte evidencia en la diferencia fundamental (clustering vs. estimación de densidad) que existe entre ambos algoritmos (10 ptos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 3 3 ... 3 3 1]\n",
      "[3 0 3 ... 3 3 0]\n",
      "-28.94735451565134\n",
      "[0.01609181 0.07073507 0.04250194 0.87067118]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "gm = GaussianMixture(n_components=4, random_state=123).fit(x)\n",
    "#gm.means_\n",
    "#c = gm.predict(x)\n",
    "\n",
    "print(gm.predict(x))\n",
    "print(gm.predict(x_validation))\n",
    "print(gm.score(x))\n",
    "print(gm.weights_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "cluster = DBSCAN(eps=2 , min_samples=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
