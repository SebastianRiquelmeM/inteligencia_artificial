{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea 3 - Inteligencia artificial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'/home/ubuntu/inteligencia_artificial/Tareas/Tarea 3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item 1\n",
    "Importo dataset (10 puntos)\n",
    "Fuente: https://www.kaggle.com/datasets/ayessa/salary-prediction-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age          workclass  fnlwgt   education  education-num  \\\n",
      "0   39          State-gov   77516   Bachelors             13   \n",
      "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
      "2   38            Private  215646     HS-grad              9   \n",
      "3   53            Private  234721        11th              7   \n",
      "4   28            Private  338409   Bachelors             13   \n",
      "\n",
      "        marital-status          occupation    relationship    race      sex  \\\n",
      "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
      "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
      "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
      "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
      "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
      "\n",
      "   capital-gain  capital-loss  hours-per-week  native-country  salary  \n",
      "0          2174             0              40   United-States   <=50K  \n",
      "1             0             0              13   United-States   <=50K  \n",
      "2             0             0              40   United-States   <=50K  \n",
      "3             0             0              40   United-States   <=50K  \n",
      "4             0             0              40            Cuba   <=50K  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(21999, 15)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "dataset = pd.read_csv(\"./dataset/train22k.csv\")\n",
    "print(dataset.head())\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item 2\n",
    "Entrene el algoritmo KNN sobre los datos seleccionados y aplique predicciones con algún (sub)conjunto DISJUNTO de prueba. Adicionalmente, utilice 3 métricas (a su elección) de error y compárelas entre sí. (15 ptos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando actualmente K= 1 , mejor k= 1 , mayor precision:  0.7239159250142019\n",
      "Procesando actualmente K= 2 , mejor k= 2 , mayor precision:  0.7814807801552737\n",
      "Procesando actualmente K= 3 , mejor k= 2 , mayor precision:  0.7814807801552737\n",
      "Procesando actualmente K= 4 , mejor k= 4 , mayor precision:  0.7832796818784321\n",
      "Score_train:  0.805945724805673\n",
      "score_validation:  0.7954932777882977\n",
      "accuracy_score: 0.805945724805673\n",
      "hamming_loss: 0.19405427519432702\n",
      "jaccard_score: 0.2177020340846619\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\"\"\" el siguiente es para asociar strings a numeros \"\"\"\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "#print(type(dataset.iloc[0,1]))\n",
    "#print(isinstance(dataset.iloc[0,1], str))\n",
    "#print(dataset.head())\n",
    "\"\"\" Declaro el encoder de string a numeros \"\"\"\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "def column_string_to_int(columnas, dataset_validation):\n",
    "     \"\"\" For para iterar el dataset en columnas\"\"\"\n",
    "     for i in range(columnas):\n",
    "          \"\"\"  \n",
    "          En realidad el dataset es un dataframe de pandas, este tiene propiedades para\n",
    "          acceder a él. 'iloc' sirve para acceder a él como una matriz con indices\n",
    "          de fila y columna [x,y].\n",
    "\n",
    "          Con isisntance() puedo ver si la primera fila de datos en cada columna es un string,\n",
    "          ya que en estos casos debo aplicar la conversion a números \"\"\"\n",
    "          if isinstance(dataset_validation.iloc[0,i], str):\n",
    "               \"\"\"\n",
    "               Con dataset.columns[i] obtengo el nombre de la columna,\n",
    "               luego convierto esa columna completa en números \"\"\"\n",
    "               string = dataset_validation.columns[i]\n",
    "               dataset_validation[string] = encoder.fit_transform(dataset_validation[string])\n",
    "\n",
    "def best_k(x_train, y_train, x_test, y_test, max_k):\n",
    "     best_k = 0\n",
    "     best_score = 0\n",
    "     for i in range(max_k):\n",
    "          i = i+1\n",
    "          knn = KNeighborsClassifier(n_neighbors=i)\n",
    "          knn.fit(x_train, y_train)\n",
    "          score = knn.score(x_test, y_test)\n",
    "          if best_score < score:\n",
    "               best_score = score\n",
    "               best_k = i\n",
    "          print(\"Procesando actualmente K=\",i,\", mejor k=\",best_k, \", mayor precision: \", best_score)\n",
    "\n",
    "column_string_to_int(15, dataset)\n",
    "\n",
    "x = dataset.iloc[:, :14].values\n",
    "\n",
    "y = dataset['salary'].values\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=17)\n",
    "\n",
    "knn.fit(x, y)\n",
    "#Realizo una predicción\n",
    "\n",
    "dataset_validation = pd.read_csv(\"./dataset/validation.csv\")\n",
    "column_string_to_int(15, dataset_validation)\n",
    "\n",
    "x_validation = dataset_validation.iloc[:, :14].values\n",
    "y_validation = dataset_validation['salary'].values\n",
    "\n",
    "#knn.predict(x_validation[1].reshape(1,-1))[0]\n",
    "#best_k(x,y,x_validation,y_validation,4)\n",
    "\n",
    "y_pred = knn.predict(x)\n",
    "\n",
    "score_train = knn.score(x,y)\n",
    "score_validation = knn.score(x_validation,y_validation)\n",
    "print(\"Score_train: \", score_train)\n",
    "print(\"score_validation: \", score_validation)\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "print(\"accuracy_score:\", metrics.accuracy_score(y, y_pred))\n",
    "\n",
    "print(\"hamming_loss:\", metrics.hamming_loss(y, y_pred))\n",
    "print(\"jaccard_score:\", metrics.jaccard_score(y, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item 3\n",
    "Entrene el algoritmo de Regresión Lineal ahora con los mismos datos seleccionados, aplicando también predicciones sobre el mismo (sub)conjunto DISJUNTO de prueba de la parte anterior. Elija alguna métrica de error de entre las tres de la parte anterior y compare los errores, dando una explicación de qué sucede. (15 ptos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mseaborn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msb\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m      6\u001b[0m get_ipython()\u001b[39m.\u001b[39mrun_line_magic(\u001b[39m'\u001b[39m\u001b[39mmatplotlib\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39minline\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "# Imports necesarios\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "plt.rcParams['figure.figsize'] = (16, 9)\n",
    "plt.style.use('ggplot')\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "#cargamos los datos de entrada\n",
    "data = pd.read_csv(\"Datos22mil.csv\")\n",
    "#veamos cuantas dimensiones y registros contiene\n",
    "data\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "\"\"\" For para iterar el dataset \"\"\"\n",
    "for i in range(15):\n",
    "     \"\"\"  \n",
    "     En realidad el dataset es un dataframe de pandas, este tiene propiedades para\n",
    "     acceder a él. 'iloc' sirve para acceder a él como una matriz con indices\n",
    "     de fila y columna [x,y].\n",
    "\n",
    "     Con isisntance puedo ver si la primera fila de datos en cada columna es un string,\n",
    "     ya que en estos casos debo aplicar la conversion a números \"\"\"\n",
    "     if isinstance(data.iloc[0,i], str):\n",
    "          #print(dataset.columns[i], dataset.iloc[0,i])\n",
    "          #print(\"type column: \", type(dataset.columns[i]),\" column:\", dataset.columns[i])\n",
    "          #dataset[dataset.columns[i]] = encoder.fit_transform(dataset.columns[i])\n",
    "          \"\"\"\n",
    "          Con dataset.columns[i] obtengo el nombre de la columna,\n",
    "          luego convierto esa columna completa en números \"\"\"\n",
    "          string = data.columns[i]\n",
    "          data[string] = encoder.fit_transform(data[string])\n",
    "\n",
    "\n",
    "\n",
    "# Asignamos nuestra variable de entrada X para entrenamiento y las etiquetas Y.\n",
    "\n",
    "X_train = data.iloc[:, :14].values\n",
    "#Nocumple = db[db.salary.str.contains('<=50K')]\n",
    "\n",
    "y_train = data['salary'].values\n",
    "\n",
    "# Creamos el objeto de Regresión Linear\n",
    "regr = linear_model.LinearRegression()\n",
    " \n",
    "# Entrenamos nuestro modelo\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred = regr.predict(X_train)\n",
    "#llamamos otro dataset...\n",
    "data_validation = pd.read_csv(\"valitation.csv\")\n",
    "\n",
    "for i in range(15):\n",
    "     if isinstance(data_validation.iloc[0,i], str):\n",
    "          string = data_validation.columns[i]\n",
    "          data_validation[string] = encoder.fit_transform(data_validation[string])\n",
    "\n",
    "#print(dataset_validation.head())\n",
    "X_train_validation = data_validation.iloc[:, :14].values\n",
    "y_train_validation = data_validation['salary'].values\n",
    "y_pred1 = regr.predict(X_train_validation)\n",
    "\"\"\" Los datos de salario <=50k son 0 y los >50 son 1 \"\"\"\n",
    "#y_predict = regr.predict(X_train_validation.iloc[:, :14])\n",
    "#for i in range(20): \n",
    "     #if(regr.predict(X_train_validation[i].reshape(1,-1))[0] == 1):\n",
    "          #print(\">50\")\n",
    "     #else:\n",
    "          #print(\"<=50k\")\n",
    "     #print(knn.predict(x_validation[i].reshape(1,-1))[0])\n",
    "\n",
    "\n",
    "#metricas score...\n",
    "\n",
    "from sklearn import metrics\n",
    "metrics.r2_score(y_train, y_pred)\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "metrics.r2_score(y_train_validation, y_pred1)\n",
    "\n",
    "\n",
    "#listoco...\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item 4\n",
    "Tome su mismo dataset y entrene dos algoritmos de clasificación: Gaussian Mixture Model y DBSCAN. Evalúe estos algoritmos sobre el mismo (sub)conjunto DISJUNTO de las partes 2 y 3. Analice la diferencia en los resultados entre los algoritmos (10 ptos). Asimismo, indique y aporte evidencia en la diferencia fundamental (clustering vs. estimación de densidad) que existe entre ambos algoritmos (10 ptos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "gm = GaussianMixture(n_components=4, random_state=123).fit(x)\n",
    "#gm.means_\n",
    "#c = gm.predict(x)\n",
    "\n",
    "print(gm.predict(x))\n",
    "print(gm.predict(x_validation))\n",
    "print(gm.score(x))\n",
    "print(gm.weights_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
